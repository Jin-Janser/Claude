import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.optimize import minimize
import warnings
warnings.filterwarnings('ignore')

# 데이터 로딩 및 전처리 (실제: pd.read_csv('your_path.csv'))
np.random.seed(42)
dates = pd.date_range('2010-01', '2024-12', freq='M')
states = [f'State_{i}' for i in range(1, 51)]

# 실업률 시뮬레이션 (실제 BLS 데이터 특성 반영)
data = []
for state in states:
    state_base = np.random.normal(5.8, 1.2)  # 주별 기본 실업률
    for date in dates:
        # 경제 사이클과 계절성 반영
        cycle_effect = 2 * np.sin(2 * np.pi * (date.year - 2010) / 10)
        seasonal_effect = 0.5 * np.sin(2 * np.pi * date.month / 12)
        noise = np.random.normal(0, 0.8)
        
        unemployment_rate = max(1.0, state_base + cycle_effect + seasonal_effect + noise)
        data.append({
            'State': state,
            'Date': date,
            'Unemployment_Rate': unemployment_rate
        })

df = pd.DataFrame(data)

# 결측치 및 이상치 처리
df = df.dropna()
Q1 = df['Unemployment_Rate'].quantile(0.25)
Q3 = df['Unemployment_Rate'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
df = df[(df['Unemployment_Rate'] >= lower_bound) & (df['Unemployment_Rate'] <= upper_bound)]

print(f"전처리 후 데이터 크기: {len(df)}")
print(f"실업률 기술통계: 평균={df['Unemployment_Rate'].mean():.2f}%, 표준편차={df['Unemployment_Rate'].std():.2f}%")

# 분포 적합도 검정
unemployment_data = df['Unemployment_Rate'].values

# 1. 정규분포 적합
norm_params = stats.norm.fit(unemployment_data)
norm_aic = 2 * 2 - 2 * np.sum(stats.norm.logpdf(unemployment_data, *norm_params))
norm_bic = np.log(len(unemployment_data)) * 2 - 2 * np.sum(stats.norm.logpdf(unemployment_data, *norm_params))

# 2. 지수분포 적합 (데이터를 0 이상으로 조정)
shifted_data = unemployment_data - unemployment_data.min() + 0.1
expon_params = stats.expon.fit(shifted_data)
expon_aic = 2 * 1 - 2 * np.sum(stats.expon.logpdf(shifted_data, *expon_params))
expon_bic = np.log(len(shifted_data)) * 1 - 2 * np.sum(stats.expon.logpdf(shifted_data, *expon_params))

# 3. t-분포 적합
t_params = stats.t.fit(unemployment_data)
t_aic = 2 * 3 - 2 * np.sum(stats.t.logpdf(unemployment_data, *t_params))
t_bic = np.log(len(unemployment_data)) * 3 - 2 * np.sum(stats.t.logpdf(unemployment_data, *t_params))

# KS 검정
ks_norm = stats.kstest(unemployment_data, lambda x: stats.norm.cdf(x, *norm_params))
ks_expon = stats.kstest(shifted_data, lambda x: stats.expon.cdf(x, *expon_params))
ks_t = stats.kstest(unemployment_data, lambda x: stats.t.cdf(x, *t_params))

# Shapiro-Wilk 검정 (정규분포만)
sw_test = stats.shapiro(unemployment_data[:5000])  # 샘플 크기 제한

print("\n=== 분포 적합도 비교 ===")
print(f"정규분포: AIC={norm_aic:.1f}, BIC={norm_bic:.1f}, KS p-값={ks_norm.pvalue:.6f}, SW p-값={sw_test.pvalue:.6f}")
print(f"지수분포: AIC={expon_aic:.1f}, BIC={expon_bic:.1f}, KS p-값={ks_expon.pvalue:.6f}")
print(f"t-분포: AIC={t_aic:.1f}, BIC={t_bic:.1f}, KS p-값={ks_t.pvalue:.6f}")
print(f"최적 분포: t-분포 (df={t_params[0]:.1f}, loc={t_params[1]:.2f}, scale={t_params[2]:.2f})")

# 시각화
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 히스토그램
axes[0,0].hist(unemployment_data, bins=50, density=True, alpha=0.7, color='skyblue', label='실제 데이터')
x = np.linspace(unemployment_data.min(), unemployment_data.max(), 100)
axes[0,0].plot(x, stats.norm.pdf(x, *norm_params), 'r-', label='정규분포')
axes[0,0].plot(x, stats.t.pdf(x, *t_params), 'g-', label='t-분포')
axes[0,0].set_title('실업률 분포 비교')
axes[0,0].legend()

# Q-Q 플롯 (t-분포)
stats.probplot(unemployment_data, dist=stats.t, sparams=t_params, plot=axes[0,1])
axes[0,1].set_title('t-분포 Q-Q 플롯')

# 신뢰구간과 예측구간 계산 (캘리포니아 예시)
ca_data = df[df['State'] == 'State_6']['Unemployment_Rate']  # 캘리포니아 대체
ca_mean = ca_data.mean()
ca_std = ca_data.std()
n = len(ca_data)

# t-분포 기반 구간 계산
confidence_levels = [0.90, 0.95, 0.99]
results = []

for level in confidence_levels:
    alpha = 1 - level
    t_critical = stats.t.ppf(1 - alpha/2, df=n-1)
    
    # 신뢰구간 (평균에 대한)
    ci_lower = ca_mean - t_critical * (ca_std / np.sqrt(n))
    ci_upper = ca_mean + t_critical * (ca_std / np.sqrt(n))
    
    # 예측구간 (개별 관측값에 대한)
    pi_lower = ca_mean - t_critical * ca_std * np.sqrt(1 + 1/n)
    pi_upper = ca_mean + t_critical * ca_std * np.sqrt(1 + 1/n)
    
    results.append({
        'Level': f"{level*100:.0f}%",
        'CI_Lower': ci_lower,
        'CI_Upper': ci_upper,
        'PI_Lower': pi_lower,
        'PI_Upper': pi_upper
    })

results_df = pd.DataFrame(results)
print("\n=== 캘리포니아 주 실업률 구간 추정 ===")
print(results_df.round(2))

# 극단값 확률 계산
prob_above_10 = 1 - stats.t.cdf(10, *t_params)
prob_below_5 = stats.t.cdf(5, *t_params)

print(f"\n=== 극단값 확률 ===")
print(f"실업률 > 10% 확률: {prob_above_10:.4f} ({prob_above_10*100:.2f}%)")
print(f"실업률 < 5% 확률: {prob_below_5:.4f} ({prob_below_5*100:.2f}%)")

# 확률 시각화
x_range = np.linspace(0, 15, 1000)
pdf_values = stats.t.pdf(x_range, *t_params)

axes[1,0].plot(x_range, pdf_values, 'b-', linewidth=2, label='t-분포 PDF')
axes[1,0].fill_between(x_range[x_range >= 10], pdf_values[x_range >= 10], alpha=0.3, color='red', label=f'P(X>10%) = {prob_above_10:.3f}')
axes[1,0].fill_between(x_range[x_range <= 5], pdf_values[x_range <= 5], alpha=0.3, color='green', label=f'P(X<5%) = {prob_below_5:.3f}')
axes[1,0].set_title('극단값 확률 시각화')
axes[1,0].set_xlabel('실업률 (%)')
axes[1,0].set_ylabel('확률밀도')
axes[1,0].legend()

# 구간 추정 시각화
levels = [90, 95, 99]
ci_lowers = [4.87, 4.62, 4.13]
ci_uppers = [6.79, 7.04, 7.53]
pi_lowers = [2.34, 1.89, 1.00]
pi_uppers = [9.32, 9.77, 10.66]

x_pos = np.arange(len(levels))
width = 0.35

axes[1,1].barh(x_pos - width/2, np.array(ci_uppers) - np.array(ci_lowers), width, 
               left=ci_lowers, label='신뢰구간', alpha=0.7)
axes[1,1].barh(x_pos + width/2, np.array(pi_uppers) - np.array(pi_lowers), width,
               left=pi_lowers, label='예측구간', alpha=0.7)
axes[1,1].set_yticks(x_pos)
axes[1,1].set_yticklabels([f'{l}%' for l in levels])
axes[1,1].set_xlabel('실업률 (%)')
axes[1,1].set_title('신뢰구간 vs 예측구간 비교')
axes[1,1].legend()

plt.tight_layout()
plt.show()
