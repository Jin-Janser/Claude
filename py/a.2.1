import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
from category_encoders import TargetEncoder
import shap
import warnings
warnings.filterwarnings('ignore')

# 1. 데이터 로드 및 전처리
def load_and_preprocess_data():
    # 실제 환경에서는 파일 경로 수정 필요
    try:
        df = pd.read_csv('train.csv')
    except FileNotFoundError:
        # 샘플 데이터 생성 (실제 데이터 부재 시)
        np.random.seed(42)
        n = 1460
        df = pd.DataFrame({
            'Id': range(1, n+1),
            'SalePrice': np.random.lognormal(12, 0.4, n),
            'GrLivArea': np.random.normal(1500, 500, n),
            'OverallQual': np.random.randint(1, 11, n),
            'TotalBsmtSF': np.random.normal(1000, 400, n),
            'GarageCars': np.random.randint(0, 4, n),
            'YearBuilt': np.random.randint(1900, 2010, n),
            'YearRemodAdd': np.random.randint(1950, 2010, n),
            'Neighborhood': np.random.choice(['NAmes', 'CollgCr', 'OldTown'], n),
            'MSZoning': np.random.choice(['RL', 'RM', 'FV'], n)
        })
    
    # 변수 분류
    numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_vars = df.select_dtypes(include=['object']).columns.tolist()
    
    # Id 제거
    if 'Id' in numeric_vars:
        numeric_vars.remove('Id')
    if 'SalePrice' in numeric_vars:
        numeric_vars.remove('SalePrice')
    
    return df, numeric_vars, categorical_vars

# 2. 결측치 처리
def handle_missing_values(df, numeric_vars, categorical_vars):
    # 연속형 변수 MICE 대체
    imputer = IterativeImputer(random_state=42, max_iter=10)
    df[numeric_vars] = imputer.fit_transform(df[numeric_vars])
    
    # 범주형 변수 최빈값 대체
    for col in categorical_vars:
        df[col].fillna(df[col].mode()[0], inplace=True)
    
    return df

# 3. 파생변수 생성
def create_derived_variables(df):
    # RemodelAge: 리모델링 후 경과년수
    if 'YearRemodAdd' in df.columns and 'YearBuilt' in df.columns:
        df['RemodelAge'] = df['YearRemodAdd'] - df['YearBuilt']
    
    # TotalSF: 총 거주면적
    if 'GrLivArea' in df.columns and 'TotalBsmtSF' in df.columns:
        df['TotalSF'] = df['GrLivArea'] + df['TotalBsmtSF']
    
    return df

# 4. Target Encoding
def apply_target_encoding(df, categorical_vars, target_col='SalePrice'):
    encoder = TargetEncoder()
    encoded_vars = []
    
    for col in categorical_vars:
        encoded_col = f"{col}_Enc"
        df[encoded_col] = encoder.fit_transform(df[col], df[target_col])
        encoded_vars.append(encoded_col)
    
    return df, encoded_vars

# 5. VIF 기반 다중공선성 제거
def remove_multicollinearity(X, threshold=5):
    X_const = sm.add_constant(X)
    vif_data = pd.DataFrame()
    vif_data["Variable"] = X_const.columns
    vif_data["VIF"] = [variance_inflation_factor(X_const.values, i) 
                       for i in range(X_const.shape[1])]
    
    # VIF > threshold인 변수 제거
    high_vif_vars = vif_data[vif_data["VIF"] > threshold]["Variable"].tolist()
    if 'const' in high_vif_vars:
        high_vif_vars.remove('const')
    
    X_reduced = X.drop(columns=high_vif_vars, errors='ignore')
    return X_reduced, vif_data

# 6. 정규화 모델 비교
def compare_regularization_models(X, y):
    kfold = KFold(n_splits=10, shuffle=True, random_state=42)
    
    models = {
        'Ridge': Ridge(),
        'Lasso': Lasso(),
        'ElasticNet': ElasticNet()
    }
    
    results = {}
    for name, model in models.items():
        cv_scores = cross_val_score(model, X, y, cv=kfold, 
                                   scoring='neg_mean_squared_error')
        results[name] = {
            'RMSE': np.sqrt(-cv_scores.mean()),
            'Std': cv_scores.std()
        }
    
    return results

# 7. 최종 모델 구축 및 진단
def build_final_model(X, y):
    # 상수항 추가
    X_const = sm.add_constant(X)
    
    # OLS 모델 적합
    model = sm.OLS(y, X_const).fit()
    
    return model

# 8. 모델 진단 시각화
def create_diagnostic_plots(model, X, y):
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 부분회귀 플롯
    sm.graphics.plot_partregress_grid(model, fig=fig)
    
    # Q-Q 플롯
    sm.qqplot(model.resid, line='45', fit=True, ax=axes[0,1])
    axes[0,1].set_title('잔차 Q-Q 플롯')
    
    # 등분산성 플롯
    axes[1,0].scatter(model.fittedvalues, model.resid, alpha=0.6)
    axes[1,0].axhline(y=0, color='red', linestyle='--')
    axes[1,0].set_xlabel('적합값')
    axes[1,0].set_ylabel('잔차')
    axes[1,0].set_title('잔차 vs 적합값')
    
    # SHAP 값 계산 및 시각화
    explainer = shap.LinearExplainer(model, X)
    shap_values = explainer.shap_values(X)
    
    axes[1,1].barh(range(len(X.columns)), 
                   np.abs(shap_values).mean(0)[:len(X.columns)])
    axes[1,1].set_yticks(range(len(X.columns)))
    axes[1,1].set_yticklabels(X.columns)
    axes[1,1].set_title('SHAP 중요도')
    
    plt.tight_layout()
    plt.show()

# 메인 실행
def main():
    # 데이터 로드 및 전처리
    df, numeric_vars, categorical_vars = load_and_preprocess_data()
    df = handle_missing_values(df, numeric_vars, categorical_vars)
    df = create_derived_variables(df)
    
    # Target Encoding
    df, encoded_vars = apply_target_encoding(df, categorical_vars)
    
    # 특성 변수 준비
    feature_vars = numeric_vars + encoded_vars + ['RemodelAge', 'TotalSF']
    X = df[feature_vars].fillna(0)
    y = df['SalePrice']
    
    # 다중공선성 제거
    X_reduced, vif_data = remove_multicollinearity(X)
    
    # 정규화 모델 비교
    reg_results = compare_regularization_models(X_reduced, y)
    print("정규화 모델 비교 결과:")
    for name, result in reg_results.items():
        print(f"{name}: RMSE = {result['RMSE']:.2f}")
    
    # 최종 모델 구축
    final_model = build_final_model(X_reduced, y)
    print("\n최종 모델 요약:")
    print(final_model.summary())
    
    # 진단 플롯 생성
    create_diagnostic_plots(final_model, X_reduced, y)
    
    return final_model, X_reduced, y

if __name__ == "__main__":
    model, X, y = main()
